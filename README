//Copyright (C) 2017 Aaron Mathankeri (aaron@quantifiedag.com)
//License: QuantifiedAG Software License.  See LICENSE.txt for full license.

PROJECT NAME
Version:
---------------------
CONTENTS OF THIS FILE
---------------------
   
 * Introduction
 * Requirements
 * Installation
 * Configuration
 * Example
 * Troubleshooting
 * FAQ
 ---------------------
 INTRODUCTION
Linear parameter models (LPMs) are simple widely used methods in supervised machine learning.
These models have several useful properties, most notably, inference has closed form solutions.
Here, data generated from a sine wave is fitted using LPMs with a polynomial basis function:

phi(x) = 1 + x + x^2 + ... + x^M

This example is inspired from Pattern Recognition and Machine Learning (PRML) Chapter 1.1.

To accelerate the learning for large scale problems, here I implement the formulas using
the Intel Math Kernel Library (MKL). For more information visit:
https://software.intel.com/en-us/mkl

These highly optimized subroutines maximize performance for multicore architectures and
speed up inference substantially.
This application is relatively light-weight and can outperform Python and R implementations
by several orders of magnitude.
 ---------------------
 REQUIREMENTS
 * Intel MKL installed locally.
 * Intel compiler supporting C++11
 * R >= 3.4.0
 ---------------------
 INSTALLATION
 Project can be cloned and run for a terminal.
 ---------------------
 CONFIGURATION
 Path to MKL must be set in 'Makefile'
 ---------------------
 EXAMPLE
 $ make
 $ [output]
  Solving Normal Equations ...
  w0 = -0.030603
  w1 = 11.7169
  w2 = -35.1367
  w3 = 23.7583
  Least Squares Error :2.6444
 ---------------------
 TROUBLESHOOTING
 Most errors will be setting the proper path to MKL
 Dynamically linking libraries will be an issure on OSX.
 Make sure to properly dynamically link in 'Makefile'
 ---------------------
 FAQ
 (1) What is the benefit of using this framework?
     For more information: //software.intel.com/en-us/mkl
 (2) What are the applications of LPMs?
     For more information: PRML by Christopher Bishop
 (3) Why not use more mainstream frameworks?
     It's faster. Much faster. This solution can be deployed
     on large compute clusters enabling rapid large-scale inference.
     Because of how light weight it is, it can be deployed on
     gateways and IoT devices where memory and compute architecture may
     be constrained.
 ---------------------